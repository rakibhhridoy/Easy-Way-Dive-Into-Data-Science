{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading dataset...\n",
      "applying feature engineering...\n",
      "splitting dataset into train and test sets...\n",
      "training started...\n",
      "Epoch is: 1 and Cost is: 7236.957044832009\n",
      "training finished.\n",
      "weights are: [-2.32335007e-02  3.47023567e-01 -1.10514113e-01 -2.09428998e-01\n",
      "  1.40125991e-01  4.10282452e-03  1.54608912e-04 -2.45955006e-03\n",
      " -5.95517495e-02 -5.19184886e-02  2.97345777e-03  2.68810472e-03\n",
      " -8.79752540e-01]\n",
      "testing the model...\n",
      "accuracy on test dataset: 0.6228070175438597\n",
      "recall on test dataset: 0.0\n",
      "precision on test dataset: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# >> FEATURE SELECTION << #\n",
    "def remove_correlated_features(X):\n",
    "    corr_threshold = 0.9\n",
    "    corr = X.corr()\n",
    "    drop_columns = np.full(corr.shape[0], False, dtype=bool)\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(i + 1, corr.shape[0]):\n",
    "            if corr.iloc[i, j] >= corr_threshold:\n",
    "                drop_columns[j] = True\n",
    "    columns_dropped = X.columns[drop_columns]\n",
    "    X.drop(columns_dropped, axis=1, inplace=True)\n",
    "    return columns_dropped\n",
    "\n",
    "\n",
    "def remove_less_significant_features(X, Y):\n",
    "    sl = 0.05\n",
    "    regression_ols = None\n",
    "    columns_dropped = np.array([])\n",
    "    for itr in range(0, len(X.columns)):\n",
    "        regression_ols = sm.OLS(Y, X).fit()\n",
    "        max_col = regression_ols.pvalues.idxmax()\n",
    "        max_val = regression_ols.pvalues.max()\n",
    "        if max_val > sl:\n",
    "            X.drop(max_col, axis='columns', inplace=True)\n",
    "            columns_dropped = np.append(columns_dropped, [max_col])\n",
    "        else:\n",
    "            break\n",
    "    regression_ols.summary()\n",
    "    return columns_dropped\n",
    "\n",
    "\n",
    "##############################\n",
    "\n",
    "\n",
    "# >> MODEL TRAINING << #\n",
    "def compute_cost(W, X, Y):\n",
    "    # calculate hinge loss\n",
    "    N = X.shape[0]\n",
    "    distances = 1 - Y * (np.dot(X, W))\n",
    "    distances[distances < 0] = 0  # equivalent to max(0, distance)\n",
    "    hinge_loss = regularization_strength * (np.sum(distances) / N)\n",
    "\n",
    "    # calculate cost\n",
    "    cost = 1 / 2 * np.dot(W, W) + hinge_loss\n",
    "    return cost\n",
    "\n",
    "\n",
    "# I haven't tested it but this same function should work for\n",
    "# vanilla and mini-batch gradient descent as well\n",
    "def calculate_cost_gradient(W, X_batch, Y_batch):\n",
    "    # if only one example is passed (eg. in case of SGD)\n",
    "    if type(Y_batch) == np.float64:\n",
    "        Y_batch = np.array([Y_batch])\n",
    "        X_batch = np.array([X_batch])  # gives multidimensional array\n",
    "\n",
    "    distance = 1 - (Y_batch * np.dot(X_batch, W))\n",
    "    dw = np.zeros(len(W))\n",
    "\n",
    "    for ind, d in enumerate(distance):\n",
    "        if max(0, d) == 0:\n",
    "            di = W\n",
    "        else:\n",
    "            di = W - (regularization_strength * Y_batch[ind] * X_batch[ind])\n",
    "        dw += di\n",
    "\n",
    "    dw = dw/len(Y_batch)  # average\n",
    "    return dw\n",
    "\n",
    "\n",
    "def sgd(features, outputs):\n",
    "    max_epochs = 2\n",
    "    weights = np.zeros(features.shape[1])\n",
    "    nth = 0\n",
    "    prev_cost = float(\"inf\")\n",
    "    cost_threshold = 0.01  # in percent\n",
    "    # stochastic gradient descent\n",
    "    for epoch in range(1, max_epochs):\n",
    "        # shuffle to prevent repeating update cycles\n",
    "        X, Y = shuffle(features, outputs)\n",
    "        for ind, x in enumerate(X):\n",
    "            ascent = calculate_cost_gradient(weights, x, Y[ind])\n",
    "            weights = weights - (learning_rate * ascent)\n",
    "\n",
    "        # convergence check on 2^nth epoch\n",
    "        if epoch == 2 ** nth or epoch == max_epochs - 1:\n",
    "            cost = compute_cost(weights, features, outputs)\n",
    "            print(\"Epoch is: {} and Cost is: {}\".format(epoch, cost))\n",
    "            # stoppage criterion\n",
    "            if abs(prev_cost - cost) < cost_threshold * prev_cost:\n",
    "                return weights\n",
    "            prev_cost = cost\n",
    "            nth += 1\n",
    "    return weights\n",
    "\n",
    "\n",
    "########################\n",
    "\n",
    "\n",
    "def init():\n",
    "    print(\"reading dataset...\")\n",
    "    # read data in pandas (pd) data frame\n",
    "    data = pd.read_csv('./data/data.csv')\n",
    "\n",
    "    # drop last column (extra column added by pd)\n",
    "    # and unnecessary first column (id)\n",
    "    data.drop(data.columns[[-1, 0]], axis=1, inplace=True)\n",
    "\n",
    "    print(\"applying feature engineering...\")\n",
    "    # convert categorical labels to numbers\n",
    "    diag_map = {'M': 1.0, 'B': -1.0}\n",
    "    data['diagnosis'] = data['diagnosis'].map(diag_map)\n",
    "\n",
    "    # put features & outputs in different data frames\n",
    "    Y = data.loc[:, 'diagnosis']\n",
    "    X = data.iloc[:, 1:]\n",
    "\n",
    "    # filter features\n",
    "    remove_correlated_features(X)\n",
    "    remove_less_significant_features(X, Y)\n",
    "\n",
    "    # normalize data for better convergence and to prevent overflow\n",
    "    X_normalized = MinMaxScaler().fit_transform(X.values)\n",
    "    X = pd.DataFrame(X_normalized)\n",
    "\n",
    "    # insert 1 in every row for intercept b\n",
    "    X.insert(loc=len(X.columns), column='intercept', value=1)\n",
    "\n",
    "    # split data into train and test set\n",
    "    print(\"splitting dataset into train and test sets...\")\n",
    "    X_train, X_test, y_train, y_test = tts(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # train the model\n",
    "    print(\"training started...\")\n",
    "    W = sgd(X_train.to_numpy(), y_train.to_numpy())\n",
    "    print(\"training finished.\")\n",
    "    print(\"weights are: {}\".format(W))\n",
    "\n",
    "    # testing the model\n",
    "    print(\"testing the model...\")\n",
    "    y_train_predicted = np.array([])\n",
    "    for i in range(X_train.shape[0]):\n",
    "        yp = np.sign(np.dot(X_train.to_numpy()[i], W))\n",
    "        y_train_predicted = np.append(y_train_predicted, yp)\n",
    "\n",
    "    y_test_predicted = np.array([])\n",
    "    for i in range(X_test.shape[0]):\n",
    "        yp = np.sign(np.dot(X_test.to_numpy()[i], W))\n",
    "        y_test_predicted = np.append(y_test_predicted, yp)\n",
    "\n",
    "    print(\"accuracy on test dataset: {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "    print(\"recall on test dataset: {}\".format(recall_score(y_test, y_test_predicted)))\n",
    "    print(\"precision on test dataset: {}\".format(recall_score(y_test, y_test_predicted)))\n",
    "\n",
    "\n",
    "# set hyper-parameters and call init\n",
    "regularization_strength = 10000\n",
    "learning_rate = 0.000001\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying feature engineering...\n",
      "splitting dataset into train and test sets...\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# drop last column (extra column added by pd)\n",
    "# and unnecessary first column (id)\n",
    "data.drop(data.columns[[-1, 0]], axis=1, inplace=True)\n",
    "\n",
    "print(\"applying feature engineering...\")\n",
    "# convert categorical labels to numbers\n",
    "diag_map = {'M': 1.0, 'B': -1.0}\n",
    "data['diagnosis'] = data['diagnosis'].map(diag_map)\n",
    "\n",
    "# put features & outputs in different data frames\n",
    "Y = data.loc[:, 'diagnosis']\n",
    "X = data.iloc[:, 1:]\n",
    "\n",
    "# filter features\n",
    "remove_correlated_features(X)\n",
    "remove_less_significant_features(X, Y)\n",
    "\n",
    "# normalize data for better convergence and to prevent overflow\n",
    "X_normalized = MinMaxScaler().fit_transform(X.values)\n",
    "X = pd.DataFrame(X_normalized)\n",
    "\n",
    "# insert 1 in every row for intercept b\n",
    "X.insert(loc=len(X.columns), column='intercept', value=1)\n",
    "\n",
    "# split data into train and test set\n",
    "print(\"splitting dataset into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = tts(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is: 1 and Cost is: 7315.472491416633\n",
      "weights are: [-4.35306770e-02  3.45350156e-01 -1.28731898e-01 -2.31821474e-01\n",
      "  1.37026343e-01 -4.13242941e-03 -7.03199116e-04 -4.12065153e-03\n",
      " -6.90538524e-02 -7.36492534e-02 -1.13911560e-02 -9.91293385e-03\n",
      " -9.29731256e-01]\n"
     ]
    }
   ],
   "source": [
    "W = sgd(X_train.to_numpy(), y_train.to_numpy())\n",
    "print(\"weights are: {}\".format(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is: 1 and Cost is: 7222.079227476714\n"
     ]
    }
   ],
   "source": [
    "features = X_train.to_numpy()\n",
    "outputs = y_train.to_numpy()\n",
    "\n",
    "max_epochs = 2\n",
    "weights = np.zeros(features.shape[1])\n",
    "nth = 0\n",
    "prev_cost = float(\"inf\")\n",
    "cost_threshold = 0.01  # in percent\n",
    "# stochastic gradient descent\n",
    "for epoch in range(1, max_epochs):\n",
    "    # shuffle to prevent repeating update cycles\n",
    "    X, Y = shuffle(features, outputs)\n",
    "    for ind, x in enumerate(X):\n",
    "        ascent = calculate_cost_gradient(weights, x, Y[ind])\n",
    "        weights = weights - (learning_rate * ascent)\n",
    "\n",
    "    # convergence check on 2^nth epoch\n",
    "    if epoch == 2 ** nth or epoch == max_epochs - 1:\n",
    "        cost = compute_cost(weights, features, outputs)\n",
    "        print(\"Epoch is: {} and Cost is: {}\".format(epoch, cost))\n",
    "        # stoppage criterion\n",
    "        if abs(prev_cost - cost) < cost_threshold * prev_cost:\n",
    "            weights\n",
    "        prev_cost = cost\n",
    "        nth += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.zeros(features.shape[1])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.20121745, 0.04889878, 0.26717172, 0.12426285, 0.03718993,\n",
       "         0.05246793, 0.02326515, 0.20382648, 0.04177549, 0.21283761,\n",
       "         0.11255667, 0.07910272, 1.        ],\n",
       "        [0.67974298, 0.10979381, 0.4       , 0.06276327, 0.12913272,\n",
       "         0.09026046, 0.06285354, 0.17213487, 0.02954549, 0.28811992,\n",
       "         0.32879953, 0.04335563, 1.        ],\n",
       "        [0.04058167, 0.06105904, 0.27323232, 0.11478517, 0.05095057,\n",
       "         0.07351218, 0.03474747, 0.11047547, 0.03324213, 0.4373638 ,\n",
       "         0.17642421, 0.11530893, 1.        ],\n",
       "        [0.17314846, 0.06354264, 0.23989899, 0.25652906, 0.02679703,\n",
       "         0.09341485, 0.0489899 , 0.07895435, 0.09128284, 0.26962953,\n",
       "         0.20205007, 0.23966942, 1.        ],\n",
       "        [0.44132567, 0.2628866 , 0.33181818, 0.23188711, 0.07293138,\n",
       "         0.16664163, 0.11441919, 0.33396477, 0.04308832, 0.36010038,\n",
       "         0.19534792, 0.08684245, 1.        ],\n",
       "        [0.11464322, 0.06009841, 0.31212121, 0.44860994, 0.00550425,\n",
       "         0.11542043, 0.0454798 , 0.13866263, 0.10468748, 0.61368289,\n",
       "         0.27951902, 0.3270366 , 1.        ],\n",
       "        [0.29861346, 0.06192596, 0.27373737, 0.22535805, 0.00304183,\n",
       "         0.06172079, 0.0294697 , 0.10528509, 0.01593356, 0.31189328,\n",
       "         0.27951902, 0.11025843, 1.        ],\n",
       "        [0.20933378, 0.0900656 , 0.30656566, 0.10067397, 0.04588086,\n",
       "         0.14921741, 0.0534596 , 0.1218602 , 0.02868178, 0.25378062,\n",
       "         0.18076089, 0.05260396, 1.        ],\n",
       "        [0.28204261, 0.22134489, 0.40454545, 0.26368997, 0.21488322,\n",
       "         0.12863881, 0.07744949, 0.2210646 , 0.08772439, 0.39774153,\n",
       "         0.24186872, 0.17407845, 1.        ],\n",
       "        [0.1166723 , 0.09109653, 0.15151515, 0.28390901, 0.03574144,\n",
       "         0.11038844, 0.04171717, 0.12614131, 0.06357531, 0.39576042,\n",
       "         0.16065445, 0.21080939, 1.        ]]),\n",
       " array([-1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1.]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_epochs = 2\n",
    "for epoch in range(1, max_epochs):\n",
    "    # shuffle to prevent repeating update cycles\n",
    "    X, Y = shuffle(features, outputs)\n",
    "    \n",
    "(X[:10], y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>w7</th>\n",
       "      <th>w8</th>\n",
       "      <th>w9</th>\n",
       "      <th>w10</th>\n",
       "      <th>w11</th>\n",
       "      <th>w12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.224552</td>\n",
       "      <td>0.023711</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.253791</td>\n",
       "      <td>0.035814</td>\n",
       "      <td>0.037515</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>0.104092</td>\n",
       "      <td>0.059119</td>\n",
       "      <td>0.378591</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.365573</td>\n",
       "      <td>0.368322</td>\n",
       "      <td>0.249495</td>\n",
       "      <td>0.140059</td>\n",
       "      <td>0.200181</td>\n",
       "      <td>0.138928</td>\n",
       "      <td>0.080429</td>\n",
       "      <td>0.277704</td>\n",
       "      <td>0.045265</td>\n",
       "      <td>0.433402</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.430504</td>\n",
       "      <td>0.040159</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.206403</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.073587</td>\n",
       "      <td>0.023763</td>\n",
       "      <td>0.086210</td>\n",
       "      <td>0.051967</td>\n",
       "      <td>0.359440</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.396348</td>\n",
       "      <td>0.248360</td>\n",
       "      <td>0.451010</td>\n",
       "      <td>0.228939</td>\n",
       "      <td>0.192178</td>\n",
       "      <td>0.275768</td>\n",
       "      <td>0.098838</td>\n",
       "      <td>0.344005</td>\n",
       "      <td>0.122652</td>\n",
       "      <td>0.519250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.291512</td>\n",
       "      <td>0.165651</td>\n",
       "      <td>0.374242</td>\n",
       "      <td>0.320977</td>\n",
       "      <td>0.070433</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.264823</td>\n",
       "      <td>0.101751</td>\n",
       "      <td>0.644720</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.523842</td>\n",
       "      <td>0.056186</td>\n",
       "      <td>0.255051</td>\n",
       "      <td>0.106992</td>\n",
       "      <td>0.399240</td>\n",
       "      <td>0.065251</td>\n",
       "      <td>0.045909</td>\n",
       "      <td>0.363137</td>\n",
       "      <td>0.029684</td>\n",
       "      <td>0.149904</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.105512</td>\n",
       "      <td>0.016806</td>\n",
       "      <td>0.279293</td>\n",
       "      <td>0.214195</td>\n",
       "      <td>0.078255</td>\n",
       "      <td>0.058416</td>\n",
       "      <td>0.016202</td>\n",
       "      <td>0.149555</td>\n",
       "      <td>0.135643</td>\n",
       "      <td>0.153338</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.116672</td>\n",
       "      <td>0.091097</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.283909</td>\n",
       "      <td>0.035741</td>\n",
       "      <td>0.110388</td>\n",
       "      <td>0.041717</td>\n",
       "      <td>0.126141</td>\n",
       "      <td>0.063575</td>\n",
       "      <td>0.395760</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.257017</td>\n",
       "      <td>0.047587</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.329823</td>\n",
       "      <td>0.062575</td>\n",
       "      <td>0.113393</td>\n",
       "      <td>0.029242</td>\n",
       "      <td>0.180337</td>\n",
       "      <td>0.090903</td>\n",
       "      <td>0.463118</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.371999</td>\n",
       "      <td>0.346298</td>\n",
       "      <td>0.448485</td>\n",
       "      <td>0.269798</td>\n",
       "      <td>0.118052</td>\n",
       "      <td>0.139529</td>\n",
       "      <td>0.082020</td>\n",
       "      <td>0.263686</td>\n",
       "      <td>0.065441</td>\n",
       "      <td>0.580004</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.224552  0.023711  0.416667  0.253791  0.035814  0.037515  0.025556   \n",
       "1    0.365573  0.368322  0.249495  0.140059  0.200181  0.138928  0.080429   \n",
       "2    0.430504  0.040159  0.244444  0.206403  0.040703  0.073587  0.023763   \n",
       "3    0.396348  0.248360  0.451010  0.228939  0.192178  0.275768  0.098838   \n",
       "4    0.291512  0.165651  0.374242  0.320977  0.070433  0.156578  0.074369   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "450  0.523842  0.056186  0.255051  0.106992  0.399240  0.065251  0.045909   \n",
       "451  0.105512  0.016806  0.279293  0.214195  0.078255  0.058416  0.016202   \n",
       "452  0.116672  0.091097  0.151515  0.283909  0.035741  0.110388  0.041717   \n",
       "453  0.257017  0.047587  0.295455  0.329823  0.062575  0.113393  0.029242   \n",
       "454  0.371999  0.346298  0.448485  0.269798  0.118052  0.139529  0.082020   \n",
       "\n",
       "            7         8         9  ...  w3  w4  w5  w6  w7  w8  w9  w10  w11  \\\n",
       "0    0.104092  0.059119  0.378591  ...   0   0   0   0   0   0   0    0    0   \n",
       "1    0.277704  0.045265  0.433402  ...   0   0   0   0   0   0   0    0    0   \n",
       "2    0.086210  0.051967  0.359440  ...   0   0   0   0   0   0   0    0    0   \n",
       "3    0.344005  0.122652  0.519250  ...   0   0   0   0   0   0   0    0    0   \n",
       "4    0.264823  0.101751  0.644720  ...   0   0   0   0   0   0   0    0    0   \n",
       "..        ...       ...       ...  ...  ..  ..  ..  ..  ..  ..  ..  ...  ...   \n",
       "450  0.363137  0.029684  0.149904  ...   0   0   0   0   0   0   0    0    0   \n",
       "451  0.149555  0.135643  0.153338  ...   0   0   0   0   0   0   0    0    0   \n",
       "452  0.126141  0.063575  0.395760  ...   0   0   0   0   0   0   0    0    0   \n",
       "453  0.180337  0.090903  0.463118  ...   0   0   0   0   0   0   0    0    0   \n",
       "454  0.263686  0.065441  0.580004  ...   0   0   0   0   0   0   0    0    0   \n",
       "\n",
       "     w12  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "..   ...  \n",
       "450    0  \n",
       "451    0  \n",
       "452    0  \n",
       "453    0  \n",
       "454    0  \n",
       "\n",
       "[455 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_data = pd.DataFrame(X)\n",
    "svm_data['target'] = Y\n",
    "svm_data.columns\n",
    "cols = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 'bias', 'target']\n",
    "svm_data.columns = cols\n",
    "weights = np.zeros(X.shape[1])\n",
    "weights\n",
    "weights = []\n",
    "for i in range(len(X)):\n",
    "    weights.append(0)\n",
    "svm_data['w1'] = weights\n",
    "svm_data['w2'] = weights\n",
    "svm_data['w3'] = weights\n",
    "svm_data['w4'] = weights\n",
    "svm_data['w5'] = weights\n",
    "svm_data['w6'] = weights\n",
    "svm_data['w7'] = weights\n",
    "svm_data['w8'] = weights\n",
    "svm_data['w9'] = weights\n",
    "svm_data['w10'] = weights\n",
    "svm_data['w11'] = weights\n",
    "svm_data['w12'] = weights\n",
    "svm_data.columns\n",
    "svm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.20121745 0.04889878 0.26717172 0.12426285 0.03718993 0.05246793\n",
      " 0.02326515 0.20382648 0.04177549 0.21283761 0.11255667 0.07910272\n",
      " 1.        ]\n",
      "1 [0.67974298 0.10979381 0.4        0.06276327 0.12913272 0.09026046\n",
      " 0.06285354 0.17213487 0.02954549 0.28811992 0.32879953 0.04335563\n",
      " 1.        ]\n",
      "2 [0.04058167 0.06105904 0.27323232 0.11478517 0.05095057 0.07351218\n",
      " 0.03474747 0.11047547 0.03324213 0.4373638  0.17642421 0.11530893\n",
      " 1.        ]\n",
      "3 [0.17314846 0.06354264 0.23989899 0.25652906 0.02679703 0.09341485\n",
      " 0.0489899  0.07895435 0.09128284 0.26962953 0.20205007 0.23966942\n",
      " 1.        ]\n",
      "4 [0.44132567 0.2628866  0.33181818 0.23188711 0.07293138 0.16664163\n",
      " 0.11441919 0.33396477 0.04308832 0.36010038 0.19534792 0.08684245\n",
      " 1.        ]\n",
      "5 [0.11464322 0.06009841 0.31212121 0.44860994 0.00550425 0.11542043\n",
      " 0.0454798  0.13866263 0.10468748 0.61368289 0.27951902 0.3270366\n",
      " 1.        ]\n",
      "6 [0.29861346 0.06192596 0.27373737 0.22535805 0.00304183 0.06172079\n",
      " 0.0294697  0.10528509 0.01593356 0.31189328 0.27951902 0.11025843\n",
      " 1.        ]\n",
      "7 [0.20933378 0.0900656  0.30656566 0.10067397 0.04588086 0.14921741\n",
      " 0.0534596  0.1218602  0.02868178 0.25378062 0.18076089 0.05260396\n",
      " 1.        ]\n",
      "8 [0.28204261 0.22134489 0.40454545 0.26368997 0.21488322 0.12863881\n",
      " 0.07744949 0.2210646  0.08772439 0.39774153 0.24186872 0.17407845\n",
      " 1.        ]\n",
      "9 [0.1166723  0.09109653 0.15151515 0.28390901 0.03574144 0.11038844\n",
      " 0.04171717 0.12614131 0.06357531 0.39576042 0.16065445 0.21080939\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "for ind, x in enumerate(X[:10]):\n",
    "    print(ind, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw = np.zeros(len(weights))\n",
    "dw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2012.17450118   488.98781631  2671.71717172  1242.62847515\n",
      "   371.89933007   524.67930423   232.65151515  2038.26482288\n",
      "   417.75493001  2128.37614739  1125.5667258    791.02715466\n",
      " 10000.        ]\n",
      "[ -6797.42982753  -1097.93814433  -4000.           -627.63268745\n",
      "  -1291.32717726   -902.60462042   -628.53535354  -1721.34874029\n",
      "   -295.45485953  -2881.19923397  -3287.99526907   -433.55634265\n",
      " -10000.        ]\n",
      "[  405.81670612   610.59044049  2732.32323232  1147.85172704\n",
      "   509.50570342   735.12181933   347.47474747  1104.75468839\n",
      "   332.42126501  4373.63798455  1764.24206584  1153.08933491\n",
      " 10000.        ]\n"
     ]
    }
   ],
   "source": [
    "for ind, x in enumerate(X[:3]):\n",
    "    ascent = calculate_cost_gradient(weights, x, Y[ind])\n",
    "    #weights = weights - (learning_rate * ascent)\n",
    "    print(ascent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here ascent is dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20121745 0.04889878 0.26717172 0.12426285 0.03718993 0.05246793\n",
      "  0.02326515 0.20382648 0.04177549 0.21283761 0.11255667 0.07910272\n",
      "  1.        ]] [-1.]\n"
     ]
    }
   ],
   "source": [
    "if type(Y[0]) == np.float64:\n",
    "    Y_batch = np.array([Y[0]])\n",
    "    X_batch = np.array([X[0]])\n",
    "    \n",
    "print(X_batch,Y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00140696])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance = 1 - (Y_batch * np.dot(X_batch, W))\n",
    "distance\n",
    "\n",
    "## distance is the distance from the decision boundary to support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw = np.zeros(len(weights))\n",
    "dw\n",
    "dw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.0014069629692219365\n"
     ]
    }
   ],
   "source": [
    "for ind, d in enumerate(distance):\n",
    "    print(ind,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is correct\n"
     ]
    }
   ],
   "source": [
    "if max(0,0) == 0:\n",
    "    print('It is correct')\n",
    "else:\n",
    "    print('i')\n",
    "    \n",
    "# so if the distance of support vector and decision boundary is 0, or say, our support vector is same as decision boundary we will return previous weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2012.17450118,   488.98781631,  2671.71717172,  1242.62847515,\n",
       "          371.89933007,   524.67930423,   232.65151515,  2038.26482288,\n",
       "          417.75493001,  2128.37614739,  1125.5667258 ,   791.02715466,\n",
       "        10000.        ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di = weights - (regularization_strength * Y_batch * X_batch)\n",
    "di\n",
    "dw =di\n",
    "dw\n",
    "# as our initial weights were 0, so dw += di is same as 0+di.. or we can say dw = di.. If you set any weights, that will be added with our updated weights.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2012.17450118,   488.98781631,  2671.71717172,  1242.62847515,\n",
       "          371.89933007,   524.67930423,   232.65151515,  2038.26482288,\n",
       "          417.75493001,  2128.37614739,  1125.5667258 ,   791.02715466,\n",
       "        10000.        ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw = dw/len(Y_batch)\n",
    "dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00201217, -0.00048899, -0.00267172, -0.00124263, -0.0003719 ,\n",
       "        -0.00052468, -0.00023265, -0.00203826, -0.00041775, -0.00212838,\n",
       "        -0.00112557, -0.00079103, -0.01      ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our final weights will be, weights = weights_initial - (learning rate * dw)\n",
    "# weights_1 = 0 - (0.000001 * 2012.17450118)\n",
    "\n",
    "weights = weights - (learning_rate * dw)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, d in enumerate(distance):\n",
    "    if max(0, d) == 0:\n",
    "        di = weights\n",
    "    else:\n",
    "        di = weights - (regularization_strength * Y_batch[ind] * X_batch[ind])\n",
    "    dw += di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost_gradient(W, X_batch, Y_batch):\n",
    "    # if only one example is passed (eg. in case of SGD)\n",
    "    if type(Y_batch) == np.float64:\n",
    "        Y_batch = np.array([Y_batch])\n",
    "        X_batch = np.array([X_batch])  # gives multidimensional array\n",
    "\n",
    "    distance = 1 - (Y_batch * np.dot(X_batch, W))\n",
    "    dw = np.zeros(len(W))\n",
    "\n",
    "    for ind, d in enumerate(distance):\n",
    "        if max(0, d) == 0:\n",
    "            di = W\n",
    "        else:\n",
    "            di = W - (regularization_strength * Y_batch[ind] * X_batch[ind])\n",
    "        dw += di\n",
    "\n",
    "    dw = dw/len(Y_batch)  # average\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00201217, -0.00048899, -0.00267172, -0.00124263, -0.0003719 ,\n",
       "        -0.00052468, -0.00023265, -0.00203826, -0.00041775, -0.00212838,\n",
       "        -0.00112557, -0.00079103, -0.01      ]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.25769361, 0.73336457, 0.53080808, 0.64237574, 0.07818215,\n",
       "        0.62943491, 0.76717172, 0.62928585, 0.29933115, 0.50868388,\n",
       "        0.52493594, 0.40968123, 1.        ]),\n",
       " -1.0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0], outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98296337])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = features.shape[0]  ## Number of samples\n",
    "distances = 1 - outputs[0] * (np.dot(features[0], weights.T))\n",
    "distances\n",
    "#z = np.dot(fetures[0], weights.T)\n",
    "#z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 0]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [-1,-2]\n",
    "a[-1<0] = 0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.603590469673385"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[distances < 0] = 0  # equivalent to max(0, distance)  as our support vector line crosses in missclassified area..\n",
    "hinge_loss = regularization_strength * (np.sum(distances) / N)\n",
    "hinge_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21.60365256]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate cost\n",
    "cost = 1 / 2 * np.dot(weights, weights.T) + hinge_loss\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight update needed..\n"
     ]
    }
   ],
   "source": [
    "# stoppage criterion\n",
    "if abs(prev_cost - cost) < cost_threshold * prev_cost:\n",
    "    print(weights)\n",
    "else:\n",
    "    print('weight update needed..')\n",
    "#prev_cost = cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so our final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
